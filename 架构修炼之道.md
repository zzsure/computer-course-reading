#第1章 网关之道

## 1.1 认识API网关

### 1.1.1 API网关是什么
- 这里说的网关特指API网关（API Gateway），字面意思是将所有API的调用统一接入API网关层，由网关负责接入和输出
- 微服务：将原来集中一体的功能（比如商品功能、订单功能）进行拆分，每个功能模块有各自的自成体系的发布、运维等功能
- API Gateway很好地解决了微服务下客户端调用、统一接入的问题。业务团队可以专注自己的业务逻辑处理，API网关更注重安全、流量、路由等问题
- 网关与代理的区别：代理纯粹是做数据透传，协议不会发生变化。网关在数据透传的背景下，可能还会涉及到协议的转换

### 1.1.2 API网关涵盖的基本功能
- 一个API网关的基本功能包括统一接入、协议适配、流量管控与容错、以及安全防护

### 1.1.3 API网关架构示例
- 网关运行良好的环境还包括注册中心（比如通过ZooKeeper读取已发布的API接口的动态配置）。
- 为了实现高性能，数据可全部异构到缓存（比如Redis）中
- 访问日志存储放Hbase
- 如果开放网关，需要一个支持OAuth 2.0协议的授权中心
- 可以引入Nginx+Lua的方式，将一些基本的检验判断前置到应用系统之上

## 1.2 一个API的生命周期

### 1.2.1 什么是API
- Application Programming Interface
- 是一个接口，基于应用，而且是可编程的
- 入参、出参、详细的文档描述

### 1.2.2 生命周期
- RAML定义了API的Design、Build、Test、Document、Share五个过程
- Swagger定义了API的Design、Build、Document、Test、Standardize五个过程

### 1.2.3 生命周期过程
- 设计，见文知意，一个API实例是一个方法，必须有入参和出参
- 构建，开始对API内部的业务逻辑进行编程，传入的参数均需要在方法的入口处进行判断
- 文档，清晰的文档是API使用者的福音
- 测试，一个好的API是便于测试的
- 分享，将API发布出去供其他开发者使用
- 运行，对API进行监控，包括性能监控、可用率监控和调用量监控，做好报警机制的规范
- 下线，将API标记为飞起，历史记录保留系统中存储

## 1.3 API网关的基石 — 泛化调用
泛化关系标识是类与类、接口与接口之间的继承关系，UML中用实线的箭头表示。本节讲的泛化是一个动作，由个别到一般，或由具体到抽象。在网关系统中，不需要接口提供方的JAR包即可远程调用，底层和RPC调用是一致的，网络、序列化、反射这些底层技术一致。区别在于参数和返回值中的所有POJO都用Map表示。通过GenericService来调用所有的服务实现。

## 1.4 如何发布API到网关系统
需要做的是将API通过一种方式存储到网关系统能够访问的数据存储中，一般选择Redis，网关西开通需要知道服务的类名和方法名。网关系统可以提供一个API发布平台入口

## 1.5 管道技术
网关没有任何业务，在API网关里面引入了管道的概念，我们将参数校验、黑白名单、限流控制、解耦调用等都封装成一个个管道，并且按照顺序组织起来

### 1.5.1 管道实现
定义各个功能的Pipe类，将Pipe类包装成一个实现Runnable的Task(PipeTask)，再将Task(PipeTask)交给事先定义好的ThreadPool线程池处理

### 1.5.2 如何获取管道
我们在设计API网关的时候，将某个API（比如xxx.api.getOrder）发布到网关系统中就默认分配了一些基本的管道处理，比如参数校验管道、黑白名单管道等。当请求到达网关系统的时候，就可以根据API的方法名获取对应的管道。

### 1.5.3 管道信息传递
信息传递是单向的，传递的顺序依靠管道池里面管道排列的顺序。比如参数校验管道逻辑完成之后需要将请求传递到限流控制管道去处理。

### 1.5.4 管道的优点
管道链是一个主流程，好比一个大树的树干，其他子流程都可以由这些管道衍生出去，这样主流程和子流程都有很清晰的脉络。同时采取管道的方式，可以对这些管道的功能进行热插拔。比如去掉黑名单管道

### 1.5.5 责任链模式
管道技术是责任链模式的一种思维演化。管道是一种形象化思维，把这种思维用最朴实的方法是实现出来，就是管道技术。我们平时使用的过滤器或拦截器也是属于管道思维的应用。

## 1.6 一个传统网关系统有几种“死”法
我们将同步和半同步称为“传统”网关，同步网关的意思是从接收请求到调用API接口提供方的过程都是同步调用；半同步则是指将I/O请求线程和业务处理线程分开，但业务线程内部还是同步调用API请求；全异步是整个链路都是异步请求。

### 1.6.1 关注CPU
业务线程池毫无疑问是在CPU里面运行的，线程是计算机CPU最宝贵的资源，我们一定要关注CPU利用率和CPU负载
- CPU利用率：显示的是程序再运行期间时占用CPU百分比
- CPU负载：显示一段时间内正在使用和等待使用CPU的平均任务数
CPU利用率高，并不意味着负载一定大，两者没有必然联系。有的程序可能涉及的计算量比较大，CPU利用率就高。不管CPU利用率是高是低，跟后面有多少人（任务）在排队没有必然联系。

### 1.6.2 关注磁盘
两个重要指标分别是磁盘使用率和磁盘负载百分比。磁盘负载百分比命令为iostat -x 110，如果%util接近100%，则说明产恒的I/O请求太多，I/O系统已经满负荷，该磁盘可能存在瓶颈。

### 1.6.3 关注网络
在一个RPC环境下，网络占据了一次RPC调用所耗时间的很大比重。网络质量的好坏直接影响了一次请求从进入API网关到返给用户响应的时间长短。

## 1.7 Servlet 3异步原理与实践

### 1.7.1 什么是Servlet
Servlet是基于Java的Web组件，可以编译成无关平台的字节码，被基于Java技术的Web服务器动态加载并运行。容器有时候也叫做Servlet引擎，是Web服务器为支持Servlet功能扩展的部分。客户端通过Servlet容器实现的request/response paradigm（请求/应答模式）与Servlet进行交互。

### 1.7.2 什么是Servlet规范
每发布一个Servlet版本发布都会对应一个Servlet版本，描述了Java Servlet API标准，定义了类、接口、方法签名的完整规范，以及附带Javadoc文档供开发人员查阅

### 1.7.3 同步、异步、阻塞、非阻塞
同步、异步是数据通信的方式，阻塞、非阻塞是一种状态。比如同步这种数据方式里面既可以有阻塞，也可以有非阻塞。使用一个县城干完的事情是同步的，有线程切换才能干完的事情是异步的。

### 1.7.4 Servlet 3的异步流程
Tomcat工作线程从HttpServletRequest中获取一个异步上下文对象AsyncContext对象，由Tomcat工作线程（此时指I/O线程）把AsyncContext对象传给业务工作线程处理，同事Tomcat工作线程归还Tomcat工作线程池中，这一步就是异步的开始。在业务处理线程中完成业务逻辑的处理，生成response返给客户端。

### 1.7.7 Tomcat NIO Connector、Servlet 3.0 Async和Spring MVC Async的关系
NIO是一种I/O的模型，与传统的BIO相比，它可以利用较少的线程处理更多的连接从而增加机器的吞吐量，Tomcat NIO Connector是Tomact的一种NIO连接模式。异步跟NIO没有任何关系，及时没有NIO也可以实现异步。Servlet 3.0 Async是指Servlet 3规范以后支持了异步处理Servlet请求，我们可以把请求和业务线程分开。Spring MVC Async是在Servlet 3异步的基础上做了一层封装。

### 1.7.8 Servlet 3非阻塞I/O
在Servlet 3.0中虽然处理请求可以实现异步，但InputStream和OutputStream的I/O操作还是阻塞的，当数据量大的request body或response body的时候，就会导致不必要的等待。Servlet 3.1以后增加了非阻塞I/O实现，仅对Servlet中的异步处理请求有效。
